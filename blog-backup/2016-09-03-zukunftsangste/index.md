---
uid: UPNmwnmTcRnwhKSUTvmv
title: Zukunftsängste
slug: zukunftsangste
alias: 2016/09/03/zukunftsngste
published_date: "2016-09-03T19:05:00+00:00"
all_tags: "[\"blog\", \"schwadroniert\"]"
publish: "True"
make_discoverable: "True"
is_page: "False"
canonical_url: ""
meta_description: ""
meta_image: "https://bear-images.sfo2.cdn.digitaloceanspaces.com/fischr/photo-1592634549335-f6be8df97b47.webp"
lang: de
class_name: ""
first_published_at: "2016-09-03T19:05:00+00:00"
---

![Maschine aus einem Maschinenwerk in Mühlhausen](https://bear-images.sfo2.cdn.digitaloceanspaces.com/fischr/4ceac707fe.webp)

Die fortwährende Innovationskraft des Menschen hat die Welt mehrfach komplett verändert. In den allermeisten Fällen zum Positiven, auch wenn nicht jede Veränderung immer sofort als positiv wahrgenommen wurde.

Ich bin ein grundsätzlich aufgeschlossener und fortschrittlich denkender Mensch. Die permanente Veränderung auf der Suche nach der Vollkommenheit, ist aus meiner Perspektive ein erstrebenswerter Zustand, obgleich man ja eigentlich nie an irgendeinem Ziel ankommen kann. Das ist meine persönliche, vielleicht etwas zu philosophische Beschreibung. Die Wikipedia fasst es etwas nüchterner zusammen:

>Geek bezeichnet heute allgemein eine Person, die sich durch großes Interesse an wissenschaftlichen oder fiktionalen Themen auszeichnet, die üblicherweise elektronischer oder phantastischer Natur sind.

Ich bin ein Geek und ich bin leider krank. Ich leide an gleich zwei Phobien: Der Mechanophobie, also der Angst vor Maschinen. Und der Cyberphobie, der Angst vor Computern.

Ich habe natürlich keine Angst vor einem Kühlschrank oder einer Brotschneidemaschine. Auch die Computertechnologie gibt mir in aller Regel meist Anlass zur Freude. Meine Angst ist die [Singularität](https://de.wikipedia.org/wiki/Technologische_Singularit%C3%A4t). Und ein, wie auch immer geartetes, Terminator-Szenario. Der große Showdown zwischen Mensch und Maschine.

Damit bin ich nicht allein. So warnten der Physik-Nobelpreisträger [Frank Wilczek](https://de.wikipedia.org/wiki/Frank_Wilczek), der Kosmologe [Max Tegmark](https://de.wikipedia.org/wiki/Max_Tegmark), der Computerwissenschaftler [Stuart Jonathan Russell](https://de.wikipedia.org/wiki/Stuart_Jonathan_Russell) und der Physiker [Stephen Hawking](https://de.wikipedia.org/wiki/Stephen_Hawking) bereits 2014 sehr eindringlich im [Independent](https://www.independent.co.uk/news/science/stephen-hawking-transcendence-looks-at-the-implications-of-artificial-intelligence-but-are-we-taking-ai-seriously-enough-9313474.html):

>Eine künstliche Intelligenz erfolgreich in Gang zu setzen, wäre das größte Ereignis der Menschheitsgeschichte. Bedauerlicher Weise könnte es auch das letzte sein, so lange wir nicht lernen, wie man die damit verbundenen Risiken vermeidet.

Nicht mehr und nicht weniger als die aktuelle wissenschaftliche Weltelite hebt den Zeigefinger und fordert einen bewussten Umgang mit der Artificial Intelligence. Einer Technologie, die, befragt man ihre Befürworter, unvorstellbare Potentiale für die Menschheit bereithält: Heilung von heute als unheilbar geltenden Krankheiten, Wohlstand, Glück und natürlich Unsterblichkeit.

Keine Frage, das klingt erstrebenswert. Aber wie kann verhindert werden, dass sich eine solche [Superintelligenz](https://de.wikipedia.org/wiki/Superintelligenz) nicht gegen ihre Erschaffer wendet? Indem wir ihr Werte vermitteln, wie [Nick Bostrom](https://de.wikipedia.org/wiki/Nick_Bostrom) es [fordert](https://www.heise.de/hintergrund/Unsere-letzte-Erfindung-3152050.html)?

>Eine Superintelligenz wäre gottähnlich. Ob Zorn oder Liebe sie antreibt, liegt an uns, die wir sie erschaffen werden. Wie alle Eltern müssen wir unser Kind mit Werten ausstatten, die im besten Interesse der Menschheit liegen. Im Grunde bringen wir einem durch uns erschaffenen Gott bei, dass er uns gut behandeln soll.
>
>Nick Bostrom

Nur, wie soll sich eine Spezies, die dem Nachbarn nicht das Schwarze unter den Fingernägeln gönnt, auf gemeinsame Werte einigen? Und was, wenn irgendwelche Schurken oder Staaten in der Hoffnung auf die ultimative Superwaffe eine solche Superintelligenz entfesseln? Es wäre wohl das Ende der Menschheit.

Aber bis dahin, ~~wird vermutlich noch der eine oder andere Tag vergehen.~~ vergehen noch mindestens 15 Jahre. Das ist zumindest der Zeitraum, den eine auf 100 Jahre angelegte [Studie](https://www.heise.de/hintergrund/Kuenstliche-Intelligenz-Freund-oder-Feind-3313710.html) der Stanford University derzeit als unproblematisch ansieht.

> Die Gefahr, dass die Menschheit im Lauf der nächsten 15 Jahre von Künstlicher Intelligenz versklavt oder eliminiert wird, ist erfreulich gering.

Beruhigend ist irgendwie anders. Aber zumindest vorerst bleibt genügend Zeit, alle in diesem Artikel gesetzten Links zu lesen und in diese sehr [hörenswerte Episode](https://www.digitalkompakt.de/podcast/kuenstliche-intelligenz-ki/) des [Podcasts digital kompakt](https://www.digitalkompakt.de/podcast) reinzuhören. Am Ende wisst ihr etwas mehr über künstliche Intelligenz und entwickelt mit etwas Glück auch eure ganz eigene Phobie.